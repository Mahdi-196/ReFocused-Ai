# ReFocused-AI 1.2B Model Training Pipeline

Production-ready GPT‚ÄëNeoX training system with practical performance optimizations

## üéØ Overview

ReFocused‚ÄëAI is a high‚Äëperformance training pipeline for a **1.2B parameter GPT‚ÄëNeoX model**. It includes authenticated Google Cloud Storage integration, device‚Äëaware model compilation, multi‚ÄëGPU support, and comprehensive monitoring. Actual speedups depend on hardware, batch size, and dataset I/O.

### üèÜ Key Features
- **1.2B parameter GPT‚ÄëNeoX architecture**
- **Device‚Äëaware `torch.compile`** after `accelerator.prepare()`
- **Multi‚ÄëGPU support (1‚Äì8 GPUs)**; scaling depends on hardware and configuration
- **Mixed precision** (bf16/fp16) to improve throughput and reduce memory use
- **Background checkpoint uploads** to GCS
- **Resume training** from local or cloud checkpoints
- **Data pipeline** with skip‚Äëexisting downloads and nested folder preservation
- **Works with large tokenized datasets** you provide
- **Real‚Äëtime monitoring** (logs, TensorBoard)

---

## üìä Dataset & step math

### Token math per step (for reference)
```python
# Per-step token consumption calculation
effective_batch_size = per_device_batch * gradient_acc * num_gpus * sequence_length
# Example: 4 √ó 4 √ó 2 √ó 1024 = 32,768 tokens/step
```

Your dataset size and coverage will vary based on the number and size of `.npz` files you train on.

---

## ‚ö° Quick Start

### üöÄ One-Command Setup
```bash
cd 05_model_training
./setup.sh
```

**What setup.sh does:**
```bash
# From actual setup.sh script content
‚úÖ Creates optimized virtual environment with Python 3.8+ validation
‚úÖ Installs PyTorch >=2.0.0 with CUDA 12.1 support for torch.compile
‚úÖ Verifies GPU compatibility and mixed precision support
‚úÖ Sets up Accelerate for multi-GPU distributed training
‚úÖ Downloads 51B token training dataset with resume capability
‚úÖ Configures Google Cloud authentication and bucket access
‚úÖ Runs comprehensive performance validation tests
```

### üéØ Production Training Commands

#### Single GPU (Development)
```bash
./start_training.sh --config production --gpus 1
# Typical: ~1‚Äì3 steps/second at 1024 context with small batches (varies by GPU)
# Memory: ~14‚Äì22GB VRAM depending on batch/precision
```

#### Multi-GPU Production (2 GPUs) ‚Äì Recommended
```bash
./start_training.sh --config production --gpus 2 --gcs-credentials /abs/path/key.json --gcp-project your-project-id
# Typical: ~2‚Äì5 steps/second combined at 1024 context (throughput scales with configuration)
# Scaling: often 60‚Äì90% depending on I/O and batch sizes
```

#### Resume from Checkpoint (Any Configuration)
```bash
# Resume training from specific checkpoint (works with local or GCS)
./start_training.sh --config production --gpus 2 --resume checkpoint-epoch0-step10000-files2 --gcs-credentials /abs/path/key.json
# Automatically downloads from GCS if not local, restores full training state
```

#### Multi-GPU (up to 8 GPUs)
```bash
./start_training.sh --config production_8gpu --gpus 8 --gcs-credentials /abs/path/key.json --gcp-project your-project-id
# Throughput improves with more GPUs; total time depends on dataset size, I/O, and precision.
# Use realistic batch sizes per GPU and monitor memory usage.
```

---

## üîß System Requirements

### Hardware Requirements
| Component | Minimum | Recommended | Maximum Performance |
|-----------|---------|-------------|-------------------|
| **GPU** | RTX 3080 (10GB) | RTX 4090 (24GB) | H100 (80GB) |
| **VRAM** | 10GB | 24GB | 80GB |
| **CPU** | 8 cores | 16+ cores | 32+ cores |
| **RAM** | 16GB | 32GB | 64GB+ |
| **Storage** | 50GB SSD | 200GB NVMe | 500GB NVMe |

### Software Requirements (tested versions)
```python
# From requirements.txt and setup.sh validation
Python: 3.8+ (tested with 3.11.x)
PyTorch: >=2.0.0 (required for torch.compile support)
CUDA: 12.1+ (for optimal H100/A100 performance)

# Core dependencies with exact versions
transformers==4.36.2          # Model architecture and tokenization
accelerate==0.25.0            # Multi-GPU distributed training
google-cloud-storage==2.13.0  # Bucket access and checkpoint uploads
datasets==2.16.1              # Data loading optimizations
tensorboard>=2.13.0           # Training monitoring
wandb>=0.15.0                 # Advanced experiment tracking
```

### Operating System Support
- **Linux**: Ubuntu 20.04+ (recommended for production)
- **Windows**: Windows 10+ with WSL2 or native support
- **macOS**: macOS 12+ (limited GPU support, CPU training available)

---

## üèóÔ∏è Architecture Details

### Model Configuration (1.2B parameters)
```python
# From configs/model_config.py - Exact implementation
GPTNeoXConfig(
    # Core architecture targeting exactly 1.2B parameters
    hidden_size=2048,              # Model width
    num_hidden_layers=24,          # Depth (24 transformer blocks)
    num_attention_heads=16,        # Attention parallelism (128 dims per head)
    intermediate_size=8192,        # FFN width (4x hidden_size)
    
    # Vocabulary and sequence configuration
    vocab_size=50257,              # Standard GPT-2 tokenizer vocabulary
    max_position_embeddings=2048,  # Maximum sequence length
    
    # Advanced architectural features
    rotary_pct=0.25,              # 25% rotary position embeddings
    use_parallel_residual=True,    # Parallel attention+FFN for speed
    hidden_act="gelu",            # GELU activation function
    layer_norm_eps=1e-5,          # Layer normalization epsilon
    
    # Training optimizations
    use_cache=False,              # Disabled during training for memory
    tie_word_embeddings=False,    # Untied for better model capacity
    attention_dropout=0.0,        # No dropout during training
    hidden_dropout=0.0,           # No dropout during training
)

# Parameter calculation: ~1.2B total parameters
# Embeddings: 50257 √ó 2048 = 102.9M
# Transformer layers: 24 √ó 45.1M = 1.08B  
# Output layer: 50257 √ó 2048 = 102.9M
# Total: ~1.2B parameters
```

### Training Configurations
```python
# From configs/training_config.py - Actual configurations

# Test Configuration (Development & Validation)
@dataclass
class TestConfig(TrainingConfig):
    max_files = 5                      # Small dataset (5 files for testing)
    max_steps = 1000                   # Quick validation run
    per_device_train_batch_size = 2    # Conservative memory usage
    gradient_accumulation_steps = 2    # Effective batch: 4 sequences
    save_steps = 200                   # Frequent saves for testing
    logging_steps = 25                 # Detailed progress logging
    warmup_steps = 10                  # Minimal warmup
    dataloader_num_workers = 2         # Conservative CPU usage

# Production Configuration (2 GPU Optimal)
@dataclass  
class ProductionConfig(TrainingConfig):
    max_files = -1                     # Full 51B token dataset
    max_steps = 25000                  # 0.016 epochs (optimal for large dataset)
    per_device_train_batch_size = 4    # High throughput per GPU
    gradient_accumulation_steps = 4    # Effective batch: 32k tokens/step
    save_steps = 1250                  # 20 checkpoints total (every 5%)
    logging_steps = 250                # 100 log points (every 1%)
    warmup_steps = 500                 # 2% warmup for gradient stability
    learning_rate = 2e-4               # Optimal for 1.2B parameter models
    weight_decay = 0.1                 # L2 regularization
    dataloader_num_workers = 4         # Full CPU parallelism

# Production 8GPU Configuration (Maximum Quality)
@dataclass
class Production8GPUConfig(TrainingConfig):
    max_files = -1                     # Complete dataset utilization
    max_steps = 590625                 # 3.036 complete epochs
    per_device_train_batch_size = 8    # High per-GPU batch size
    gradient_accumulation_steps = 4    # Effective batch: 256k tokens/step
    save_steps = 20000                 # 29 checkpoints (every 3.4%)
    logging_steps = 3000               # 200 log points (every 0.5%)
    warmup_steps = 11812               # 2% of total training steps
    learning_rate = 3e-4               # Higher LR for larger effective batch
    dataloader_num_workers = 6         # Enhanced parallelism for 8 GPUs
```

---

## üöÄ Performance Optimizations

### 1. Device-Aware Model Compilation
```python
# From train.py lines 159-167 - Critical optimization
# torch.compile placement AFTER accelerator.prepare() for device awareness
model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
    model, optimizer, train_dataloader, lr_scheduler
)

# Device-aware compilation for GPU-specific kernel optimization
if getattr(config, 'compile_model', False) and hasattr(torch, 'compile'):
    print("üöÄ Applying torch.compile after accelerator.prepare()...")
    try:
        model = torch.compile(model)
        print("‚úÖ Model compilation successful")
    except Exception as e:
        print(f"‚ö†Ô∏è  Model compilation failed: {e}")
```

**Performance Impact:**
- **20-40% speed improvement** on modern GPUs (RTX 4090, H100, A100)
- **GPU-specific kernel optimization** for actual hardware configuration
- **Multi-GPU aware compilation** for distributed training setups
- **Automatic fallback** for older PyTorch versions or unsupported hardware

### 2. Optimized Training Loop
```python
# From train.py lines 180+ - Streamlined training implementation
def training_loop():
    for step, batch in enumerate(train_dataloader):
        with accelerator.accumulate(model):
            outputs = model(**batch)
            loss = outputs.loss
            accelerator.backward(loss)
            
            # Gradient processing only when accumulated
            if accelerator.sync_gradients:
                accelerator.clip_grad_norm_(model.parameters(), config.max_grad_norm)
                optimizer.step()
                lr_scheduler.step()  # Proper scheduler placement after optimizer
                optimizer.zero_grad()
```

**Key Improvements:**
- **Removed manual accumulation wrapper** - Accelerate handles efficiently
- **Proper scheduler stepping** synchronized with gradient updates
- **Reduced Python overhead** for 5-15% training speed improvement
- **Better error handling** and memory management

### 3. Smart Checkpoint Resume System
```python
# From train.py - Comprehensive checkpoint resume functionality
def handle_checkpoint_resume(args, checkpoint_manager, accelerator, lr_scheduler):
    """Smart checkpoint resume with full state restoration"""
    if args.resume:
        print(f"üîÑ Attempting to resume training from checkpoint: {args.resume}")
        try:
            checkpoint_data = checkpoint_manager.load_checkpoint(
                accelerator=accelerator,
                checkpoint_name=args.resume,
                scheduler=lr_scheduler
            )
            
            if checkpoint_data and checkpoint_data.get('checkpoint_info'):
                # Restore complete training state
                chkp_info = checkpoint_data['checkpoint_info']
                completed_steps = chkp_info.get('step', 0)
                starting_epoch = chkp_info.get('epoch', 0)
                best_loss = chkp_info.get('best_loss', float('inf'))
                
                # Restore training metrics and history
                loss_history = checkpoint_data.get('training_metrics', {}).get('loss_history', [])
                learning_rate_history = checkpoint_data.get('training_metrics', {}).get('learning_rates', [])
                
                print(f"‚úÖ Resumed from checkpoint: {args.resume}")
                print(f"   Starting from Step: {completed_steps + 1}, Epoch: {starting_epoch}")
                print(f"   Best loss restored: {best_loss}")
                return completed_steps, starting_epoch, best_loss, loss_history, learning_rate_history
        except Exception as e:
            print(f"‚ùå Error loading checkpoint {args.resume}: {e}")
            print("   Starting training from scratch.")
    
    return 0, 0, float('inf'), [], []
```

**Resume Features:**
- **Automatic GCS download** - fetches checkpoints from cloud storage if not local
- **Complete state restoration** - model weights, optimizer state, scheduler, metrics
- **Smart batch skipping** - resumes mid-epoch without reprocessing data
- **Progress bar continuity** - starts from correct step count
- **Error resilience** - graceful fallback to fresh training if resume fails

### 4. Smart Data Pipeline with Resume Capability
```python
# From download_training_data.py - Enhanced download system
def download_with_resume(blob, data_dir):
    """Smart download preserving bucket structure with resume capability"""
    relative_path = Path(blob.name)                           # e.g., "subdir/file.npz"
    local_path = data_dir / relative_path                      # Preserves nested structure
    local_path.parent.mkdir(parents=True, exist_ok=True)       # Create directories
    
    # Skip existing files for resume capability
    if local_path.exists():
        print(f"‚è≠Ô∏è  Skipping (already exists): {relative_path}")
        return True
    
    # Download with progress tracking
    print(f"üì• Downloading: {relative_path}")
    blob.download_to_filename(local_path)
    return True
```

**Pipeline Features:**
- **Resume downloads** - never re-download existing files (50-90% time savings)
- **Preserve nested folder structure** from GCS bucket organization
- **Recursive file verification** with `glob("**/*.npz")` pattern
- **Progress tracking** with file-by-file status updates

---

## üìà Performance notes

- Expect higher throughput with bf16/fp16 and `torch.compile` on modern GPUs.
- Real‚Äëworld speed depends on: sequence length, effective batch size, GPU model/VRAM, disk/network I/O, and data loader settings.
- As a rough guide at 1024 context and small batches: single high‚Äëend consumer GPU often lands around ~1‚Äì3 steps/sec; 2 GPUs can reach ~2‚Äì5 steps/sec; larger servers can go higher.

---

## üîÑ Complete Training Workflow

### Step 1: Environment Setup and Validation
```bash
# Navigate to training directory
cd ReFocused-AI/05_model_training

# Run comprehensive automated setup
./setup.sh
```

### Step 2: Authentication and Bucket Access
```bash
# Provide credentials via flags when running training commands (no env vars required)
./start_training.sh --config test --gcs-credentials /abs/path/key.json --gcp-project your-project-id
```

### Step 3: Multi-GPU Configuration
```bash
# Configure Accelerate for distributed training
accelerate config

# Example optimal configuration for 2 GPUs:
# ‚úÖ Compute environment: This machine
# ‚úÖ Distributed type: multi-GPU
# ‚úÖ Number of machines: 1  
# ‚úÖ Number of processes: 2 (matches GPU count)
# ‚úÖ GPU IDs to use: 0,1
# ‚úÖ Mixed precision: bf16 (best for modern GPUs)
```

### Step 4: Training Execution

#### Production Training (Recommended)
```bash
# 2 GPU production training (time varies with hardware and I/O)
./start_training.sh --config production --gpus 2

# Tips:
# - Start with smaller batches; increase if memory allows.
# - Use bf16 where supported for better stability on modern GPUs.
# - Adjust dataloader workers to match your CPU and storage.
```

#### Resume Interrupted Training
```bash
# Resume from any checkpoint (automatically downloads from GCS if needed)
./start_training.sh --config production --gpus 2 --resume checkpoint-epoch0-step12500-files2 --gcs-credentials /abs/path/key.json

# What happens on resume:
# ‚úÖ Downloads checkpoint from GCS if not local
# ‚úÖ Restores model weights, optimizer state, scheduler
# ‚úÖ Continues from step 12501 (not step 0)
# ‚úÖ Preserves loss history and best loss achieved
# ‚úÖ Skips already processed batches in current epoch
```

#### Larger multi‚ÄëGPU runs
```bash
# 8 GPU training (throughput and time depend on dataset and hardware)
./start_training.sh --config production_8gpu --gpus 8
```

---

## üîç Monitoring and Debugging

### Real-Time Training Output

#### Fresh Training Start
```bash
# Typical production training output from train.py
üöÄ Starting PRODUCTION training with optimizations
  Max steps: 25000
  Batch size per device: 4
  Gradient accumulation steps: 4
  Effective batch size: 32 (4 √ó 4 √ó 2 GPUs)
  Mixed precision: bf16
  torch.compile: enabled (device-aware)
  Background uploads: enabled

üöÄ Starting training from scratch (no resume checkpoint specified).

üìà Starting optimized training loop...
üöÄ Starting fresh training, target: 25000
Step 250: loss=2.4567, lr=1.96e-04, best=2.4234 | 5.2 steps/sec | GPU: 94%/95%
Step 500: loss=2.3456, lr=1.94e-04, best=2.3234 | 5.4 steps/sec | GPU: 96%/94%  
```

#### Resume Training Output
```bash
# Resume training output showing checkpoint loading
üîÑ Attempting to resume training from checkpoint: checkpoint-epoch0-step10000-files2
üì• Downloading checkpoint from GCS...
‚úÖ Successfully downloaded checkpoint-epoch0-step10000-files2
Loading checkpoint from ./checkpoints/checkpoint-epoch0-step10000-files2
‚úÖ Restored scheduler state
‚úÖ Loaded training metrics
‚úÖ Resumed from checkpoint: checkpoint-epoch0-step10000-files2
   Starting from Step: 10001, Epoch: 0
   Best loss restored: 2.1234
   Loss history entries: 40
   Training will continue from global step 10001

üìà Starting optimized training loop...
üîÑ Resuming training from step 10000, target: 25000
üîÑ Resuming epoch 0: skipping 195 batches
Step 10250: loss=2.1567, lr=1.84e-04, best=2.1234 | 5.3 steps/sec | GPU: 95%/96%
```

#### Performance Summary
```bash
üéØ Performance Summary (Step 15000):
   Average speed: 5.3 steps/second
   GPU utilization: 95% (both GPUs)
   Memory usage: 16.2GB / 24GB per GPU
   Scaling efficiency: 92%
   torch.compile optimization: active
   Resume: Successfully continued from step 10000
```

### Performance Diagnostic Metrics
```python
# Expected training progression and targets
loss_progression = {
    "initial": 3.5-4.0,      # Untrained model baseline
    "1k_steps": 2.8-3.2,     # Basic pattern learning
    "5k_steps": 2.4-2.8,     # Context understanding
    "10k_steps": 2.0-2.4,    # Good conversational coherence
    "25k_steps": 1.8-2.2,    # Production quality
}

training_speed_benchmarks = {
    "rtx_4090_1gpu": "2.5-3.5 steps/sec",
    "rtx_4090_2gpu": "4.5-6.5 steps/sec", 
    "a100_4gpu": "12-18 steps/sec",
    "h100_8gpu": "20-35 steps/sec",
}
```

---

## üéØ Quick Command Reference

### Setup and Environment Commands
```bash
# Complete setup from scratch
./setup.sh                                   # Full automated setup (382 lines)
source venv/bin/activate                     # Activate virtual environment  
python tests/test_optimizations.py           # Validate GPU optimizations
accelerate config                            # Configure multi-GPU settings
```

### Training Execution Commands
```bash
# Development and testing
./start_training.sh --config test --gpus 1                    # Quick validation

# Production training  
./start_training.sh --config production --gpus 2              # 2 GPU production (recommended)
./start_training.sh --config production_8gpu --gpus 8         # Maximum performance

# Resume training from checkpoints
./start_training.sh --config production --gpus 2 --resume checkpoint-epoch0-step10000-files2  # Resume from step 10000
./start_training.sh --config test --resume checkpoint-epoch0-step500-files0                   # Resume test training

# Advanced options
./start_training.sh --config production --gpus 2 --max-steps 50000  # Custom steps
./start_training.sh --config production --gpus 4 --resume checkpoint-epoch0-step15000-files3 --max-steps 30000  # Resume + custom target
```

### Monitoring and Checkpoint Commands
```bash
# Real-time monitoring
nvidia-smi -l 1                              # GPU utilization (1 second intervals)
tail -f logs/training.log                    # Live training progress

# Performance analysis
tensorboard --logdir logs/ --port 6006       # TensorBoard dashboard

# Checkpoint management
gsutil ls gs://refocused-ai/checkpoints/     # List available checkpoints in GCS
ls -la ./checkpoints/                        # List local checkpoints
python test_resume.py                        # Test resume functionality

# Find and resume from latest checkpoint
gsutil ls gs://refocused-ai/checkpoints/ | tail -1 | xargs -I {} ./start_training.sh --config production --gpus 2 --resume {}
```

---

## üîÑ Checkpoint Resume System

### How Resume Works
The resume functionality automatically handles both **local and GCS checkpoints**:

1. **Check Local First**: Looks for checkpoint in `./checkpoints/`
2. **Download if Missing**: Automatically downloads from `gs://refocused-ai/checkpoints/` 
3. **Complete State Restoration**: Restores model, optimizer, scheduler, metrics, and training progress
4. **Smart Continuation**: Continues from exact step, skips processed batches

### Resume Command Examples
```bash
# Basic resume (works with any checkpoint)
./start_training.sh --config production --gpus 2 --resume checkpoint-epoch0-step12500-files2

# Resume test training
./start_training.sh --config test --resume checkpoint-epoch0-step500-files0

# Resume with custom target steps
./start_training.sh --config production --gpus 2 --resume checkpoint-epoch0-step10000-files2 --max-steps 30000
```

### Available Checkpoints
Checkpoints are saved every 1,250 steps (5% intervals) in production training:
- `checkpoint-epoch0-step1250-files0` (5% complete)
- `checkpoint-epoch0-step2500-files0` (10% complete)  
- `checkpoint-epoch0-step12500-files2` (50% complete)
- `checkpoint-epoch0-step25000-files4` (100% complete)

### Troubleshooting Resume Issues

#### ‚úÖ **Issue: "Training starts from step 0 instead of resuming"**
**Fixed!** This was the main bug that has been resolved. The training script now properly calls `checkpoint_manager.load_checkpoint()` and restores all training state.

#### **Issue: "Checkpoint not found"**
```bash
# Check available checkpoints
gsutil ls gs://refocused-ai/checkpoints/
ls -la ./checkpoints/

# Verify exact checkpoint name format
# Correct: checkpoint-epoch0-step1250-files0
# Wrong:   checkpoint-step1250 (missing epoch and files)
```

#### **Issue: "Loss jumps after resume"**
Check these messages in the output:
- ‚úÖ "Restored scheduler state"
- ‚úÖ "Loaded training metrics" 
- ‚úÖ "Best loss restored: X.XXXX"

If missing, check GCS authentication and checkpoint integrity.

#### **Issue: "GCS authentication failed"**
Run with explicit credentials flags, e.g. `--gcs-credentials /abs/path/key.json --gcp-project your-project-id`.

---

## üéâ What to expect

- Loss values and convergence rates depend on your dataset size/quality and hyperparameters.
- Training time ranges from hours to days based on GPU count, precision, and I/O.
- Checkpoints include full training state for resume and analysis.

### Inference (typical ranges)
```python
inference_specs = {
    "memory_requirements": "several GB of VRAM or CPU RAM, depending on dtype",
    "inference_speed": "~20‚Äì150 tokens/second on modern GPUs (highly hardware dependent)",
    "context_window": "up to 2048 tokens (as configured)",
    "model_format": "PyTorch checkpoint, convertible to ONNX/TensorRT",
    "compatibility": "Hugging Face Transformers, vLLM, FastAPI"
}
```

---

## üöÄ **Production Ready AI Training**

**ReFocused-AI** represents the cutting edge of efficient transformer training, delivering production-grade 1.2B parameter models with comprehensive monitoring, enterprise-level reliability, and exceptional scalability.

### **Immediate Next Steps:**
1. **Environment Setup**: `cd 05_model_training && ./setup.sh`
2. **System Validation**: `python tests/test_optimizations.py`
3. **Multi-GPU Configuration**: `accelerate config` (for 2+ GPUs)
4. **Start Production Training**: `./start_training.sh --config production --gpus 2`
5. **Monitor Progress**: `nvidia-smi -l 1` and `tail -f logs/training.log`

### **Support and Compatibility:**
- ‚úÖ **Linux Production**: Ubuntu 20.04+ with full optimization support
- ‚úÖ **Windows Development**: Native or WSL2 with complete functionality  
- ‚úÖ **Cloud Platforms**: AWS EC2, GCP Compute Engine, Azure VMs
- ‚úÖ **Hardware Range**: RTX 3080 (minimum) to H100 (maximum performance)

Performance varies by setup; measure on your hardware and adjust batch sizes, precision, and dataloader settings for best results.

**Transform your AI training workflow with enterprise-grade performance and reliability!** üöÄ

up to date